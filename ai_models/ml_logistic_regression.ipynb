{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from constants import numeric_features, categorical_features\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from ai_models.shared import load_processed_data\n",
    "from ai_models.shared import load_train_with_validation_data\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "NUMBER_OF_EPOCHS = 250",
   "id": "1323c22961a987fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df = load_processed_data()\n",
    "df = df[df[\"Target\"].isin([\"Graduate\", \"Dropout\"])]\n",
    "df[\"y\"] = (df[\"Target\"] == \"Graduate\").astype(int)\n",
    "df = df.drop(columns=[\"Target\", \"Target encoded\"], errors='ignore')"
   ],
   "id": "2b1b7ae7b8475858",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = df.drop(columns=[\"y\"])\n",
    "y = df[\"y\"].values"
   ],
   "id": "c5b948b62fa9daf4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_features = [c for c in numeric_features if c in X.columns]\n",
    "cat_features = [c for c in categorical_features if c in X.columns]"
   ],
   "id": "d090a12c168e7af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])"
   ],
   "id": "41cf71974728f833",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])"
   ],
   "id": "5ab0f40c5a26950c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_features),\n",
    "    (\"cat\", cat_pipeline, cat_features)\n",
    "])"
   ],
   "id": "c0a403081ce9a113",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_raw, X_val_raw, X_test_raw, y_train, y_val, y_test = load_train_with_validation_data(X, y)\n",
    "X_train = full_pipeline.fit_transform(X_train_raw)\n",
    "X_test = full_pipeline.transform(X_test_raw)\n",
    "X_val = full_pipeline.transform(X_val_raw)"
   ],
   "id": "f197cf4688611606",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_bias = np.hstack([np.ones((X_train.shape[0], 1)), X_train.toarray()])\n",
    "X_test_bias = np.hstack([np.ones((X_test.shape[0], 1)), X_test.toarray()])\n",
    "X_val_bias = np.hstack([np.ones((X_val.shape[0], 1)), X_val.toarray()])"
   ],
   "id": "c6c6dd38eb3715ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sigmoid(z: np.ndarray) -> np.ndarray:\n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ],
   "id": "812e8f40dff71afd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$"
   ],
   "id": "b3553e44940d778e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def cross_entropy(y_true, y_prob):\n",
    "    eps = 1e-15\n",
    "    y_prob = np.clip(y_prob, eps, 1 - eps) # Avoid log(0)\n",
    "    return -np.mean(y_true * np.log(y_prob) + (1 - y_true) * np.log(1 - y_prob))"
   ],
   "id": "b3f7b2f5ae3a568e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\mathcal{L} = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)}) \\right]\n",
    "$$"
   ],
   "id": "337ec9f31580a015"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def logistic_gd(X, y, lr=0.05, epochs=NUMBER_OF_EPOCHS, batch_size=64, lambda_l2=0.001, seed=0):\n",
    "    m, n = X.shape\n",
    "    rng = np.random.default_rng(seed)\n",
    "    w = rng.normal(scale=0.01, size=n)\n",
    "    b = 0.0\n",
    "    history = []\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        idx = rng.permutation(m)\n",
    "        for start in range(0, m, batch_size):\n",
    "            ii = idx[start:start + batch_size]\n",
    "            Xb, yb = X[ii], y[ii]\n",
    "            p = sigmoid(Xb @ w + b) #probabilities\n",
    "            error = p - yb\n",
    "            grad_w = (Xb.T @ error) / len(yb) + lambda_l2 * w # L2 regularization to avoid overfitting\n",
    "            grad_b = error.mean()\n",
    "            w -= lr * grad_w # update weights\n",
    "            b -= lr * grad_b # update bias\n",
    "\n",
    "        p_all = sigmoid(X @ w + b)\n",
    "        loss = cross_entropy(y, p_all)\n",
    "        history.append(loss)\n",
    "\n",
    "        if (ep + 1) % 20 == 0 or ep == 0:\n",
    "            pred = (p_all >= 0.5).astype(int)\n",
    "            acc = (pred == y).mean()\n",
    "            print(f\"Epoch {ep+1:3d}/{epochs}  |  loss={loss:.4f}  |  acc={acc:.3f}\")\n",
    "\n",
    "    return w, b, history"
   ],
   "id": "a9028f64d23a97cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "w, b, loss_hist = logistic_gd(X_train_bias, y_train)\n",
   "id": "df6aa9e18840baa3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate(X_set, y_set, label=\"SET\"):\n",
    "    probability = sigmoid(X_set @ w + b)\n",
    "    pred = (probability >= 0.5).astype(int)\n",
    "    print(f\"\\n{label} METRICS\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_set, pred))\n",
    "    print(\"F1-score :\", f1_score(y_set, pred))\n",
    "    print(\"AUC-ROC  :\", roc_auc_score(y_set, probability))"
   ],
   "id": "b3bad2442dbd0627",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:31:57.363272Z",
     "start_time": "2025-05-28T17:31:57.341839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluate(X_train_bias, y_train, \"TRAIN\")\n",
    "evaluate(X_test_bias, y_test, \"TEST\")\n",
    "evaluate(X_val_bias, y_val, \"VALIDATION\")"
   ],
   "id": "1c9c44c2f5e6dd96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN METRICS\n",
      "Accuracy : 0.9208972845336482\n",
      "F1-score : 0.9374805598755832\n",
      "AUC-ROC  : 0.9614175279552455\n",
      "\n",
      "TEST METRICS\n",
      "Accuracy : 0.9192660550458716\n",
      "F1-score : 0.9345238095238095\n",
      "AUC-ROC  : 0.9614195796335843\n",
      "\n",
      "VALIDATION METRICS\n",
      "Accuracy : 0.9117647058823529\n",
      "F1-score : 0.9300291545189504\n",
      "AUC-ROC  : 0.9599546870574909\n"
     ]
    }
   ],
   "execution_count": 207
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_sklearn = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    max_iter=NUMBER_OF_EPOCHS,\n",
    ")"
   ],
   "id": "7990ce4a9283e43e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_sklearn.fit(X_train, y_train)\n",
    "y_pred_train = model_sklearn.predict(X_train)\n",
    "y_pred_test  = model_sklearn.predict(X_test)"
   ],
   "id": "8b6ef91fd71dbeb5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:32:49.556563Z",
     "start_time": "2025-05-28T17:32:49.538081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_sklearn(model, X_set, y_set, label=\"SET\"):\n",
    "    probability = model.predict_proba(X_set)[:, 1]\n",
    "    pred = model.predict(X_set)\n",
    "    print(f\"\\n{label} METRICS\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_set, pred))\n",
    "    print(\"F1-score :\", f1_score(y_set, pred))\n",
    "    print(\"AUC  :\", roc_auc_score(y_set, probability))\n",
    "\n",
    "evaluate_sklearn(model_sklearn, X_train, y_train, \"TRAIN\")\n",
    "evaluate_sklearn(model_sklearn, X_test, y_test, \"TEST\")\n",
    "evaluate_sklearn(model_sklearn, X_val, y_val, \"VALIDATION\")"
   ],
   "id": "8b95c3332c43a6f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN METRICS\n",
      "Accuracy : 0.9208972845336482\n",
      "F1-score : 0.9372463315641586\n",
      "AUC-ROC  : 0.9635510488508555\n",
      "\n",
      "TEST METRICS\n",
      "Accuracy : 0.9155963302752294\n",
      "F1-score : 0.9313432835820895\n",
      "AUC-ROC  : 0.9615460267505902\n",
      "\n",
      "VALIDATION METRICS\n",
      "Accuracy : 0.90625\n",
      "F1-score : 0.9253294289897511\n",
      "AUC-ROC  : 0.960096290002832\n"
     ]
    }
   ],
   "execution_count": 208
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
