{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T13:28:06.415604Z",
     "start_time": "2025-05-30T13:27:56.602076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from time import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from constants import numeric_features, categorical_features\n",
    "from part2.shared import load_processed_data\n",
    "from part2.shared import load_train_with_validation_data"
   ],
   "id": "cfd460af6aacd93e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T13:28:06.516238Z",
     "start_time": "2025-05-30T13:28:06.426934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = load_processed_data()\n",
    "df = df[df[\"Target\"].isin([\"Graduate\", \"Dropout\"])]\n",
    "df[\"y\"] = (df[\"Target\"] == \"Graduate\").astype(int)\n",
    "df = df.drop(columns=[\"Target\", \"Target encoded\"], errors='ignore')"
   ],
   "id": "3381f124923b5aab",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T13:28:06.943049Z",
     "start_time": "2025-05-30T13:28:06.933998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = df.drop(columns=[\"y\"])\n",
    "y = df[\"y\"].values"
   ],
   "id": "1c850ea91151a08b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T13:28:06.987896Z",
     "start_time": "2025-05-30T13:28:06.981051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_features = [c for c in numeric_features if c in X.columns]\n",
    "cat_features = [c for c in categorical_features if c in X.columns]"
   ],
   "id": "25a0a193ba5f1395",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T13:28:07.088448Z",
     "start_time": "2025-05-30T13:28:07.081871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])"
   ],
   "id": "ff24dce872c90d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T13:28:07.148609Z",
     "start_time": "2025-05-30T13:28:07.142607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])"
   ],
   "id": "9ae0ada7e5d27045",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T13:28:07.200998Z",
     "start_time": "2025-05-30T13:28:07.195613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_features),\n",
    "    (\"cat\", cat_pipeline, cat_features)\n",
    "])"
   ],
   "id": "f29987eb012b4daa",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T13:28:07.342451Z",
     "start_time": "2025-05-30T13:28:07.218377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_raw, X_val_raw, X_test_raw, y_train, y_val, y_test = load_train_with_validation_data(X, y)\n",
    "X_train = full_pipeline.fit_transform(X_train_raw)\n",
    "X_test = full_pipeline.transform(X_test_raw)\n",
    "X_val = full_pipeline.transform(X_val_raw)"
   ],
   "id": "459872fbee1837c0",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T13:28:07.429762Z",
     "start_time": "2025-05-30T13:28:07.423070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_tensor(x, y, device):\n",
    "    if hasattr(x, \"toarray\"):\n",
    "        x = x.toarray()\n",
    "    return torch.tensor(x, dtype=torch.float32).to(device), torch.tensor(y, dtype=torch.float32).to(device)\n"
   ],
   "id": "8a54fa9f5f33c293",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T13:28:07.510766Z",
     "start_time": "2025-05-30T13:28:07.505453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))"
   ],
   "id": "e165cb30ff8b2287",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T13:28:07.671906Z",
     "start_time": "2025-05-30T13:28:07.663101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(X_train, y_train, device, epochs=250, batch_size=256, lr=0.05):\n",
    "    X_train_tensor, y_train_tensor = to_tensor(X_train, y_train, device)\n",
    "    model = LogisticRegressionModel(X_train.shape[1]).to(device)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in loader:\n",
    "            optimizer.zero_grad() #needed to clear gradients because PyTorch accumulates gradients by default\n",
    "            pred = model(xb).squeeze()\n",
    "            loss = loss_fn(pred, yb)\n",
    "            loss.backward() #calculate gradients using backpropagation\n",
    "            optimizer.step()\n",
    "\n",
    "    return model.eval()"
   ],
   "id": "1657c0e3de073324",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T13:28:07.760980Z",
     "start_time": "2025-05-30T13:28:07.687868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, X, y, device):\n",
    "    X_tensor, y_tensor = to_tensor(X, y, device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(X_tensor).squeeze()\n",
    "        pred_labels = (pred > 0.5).float()\n",
    "        accuracy = accuracy_score(y_tensor.cpu(), pred_labels.cpu())\n",
    "        f1 = f1_score(y_tensor.cpu(), pred_labels.cpu())\n",
    "        auc = roc_auc_score(y_tensor.cpu(), pred.cpu())\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1, \"auc\": auc}"
   ],
   "id": "db3707d1ff51a8e0",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T13:28:32.412068Z",
     "start_time": "2025-05-30T13:28:07.858460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_and_report(device_label, device):\n",
    "    print(f\"\\n=== {device_label} ===\")\n",
    "\n",
    "    start_time = time()\n",
    "    model = train_model(X_train, y_train, device)\n",
    "    duration = time() - start_time\n",
    "\n",
    "    print(f\"{device_label} TRAINING TIME: {duration:.2f} seconds\")\n",
    "\n",
    "    train_result = evaluate_model(model, X_train, y_train, device)\n",
    "    test_result = evaluate_model(model, X_test, y_test, device)\n",
    "    val_result  = evaluate_model(model, X_val, y_val, device)\n",
    "\n",
    "    print(f\"\\n{device_label} TRAIN METRICS:\")\n",
    "    print(f\"Accuracy: {train_result['accuracy']:.3f} | F1-score: {train_result['f1']:.3f} | AUC: {train_result['auc']:.3f}\")\n",
    "\n",
    "    print(f\"\\n{device_label} TEST METRICS:\")\n",
    "    print(f\"Accuracy: {test_result['accuracy']:.3f} | F1-score: {test_result['f1']:.3f} | AUC: {test_result['auc']:.3f}\")\n",
    "\n",
    "    print(f\"\\n{device_label} VALIDATION METRICS:\")\n",
    "    print(f\"Accuracy: {val_result['accuracy']:.3f} | F1-score: {val_result['f1']:.3f} | AUC: {val_result['auc']:.3f}\")\n",
    "\n",
    "run_and_report(\"CPU\", torch.device(\"cpu\"))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    run_and_report(\"GPU\", torch.device(\"cuda\"))\n",
    "else:\n",
    "    print(\"\\nGPU not available. Skipping GPU training.\")\n"
   ],
   "id": "6c93b53c651d043f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CPU ===\n",
      "CPU TRAINING TIME: 16.60 seconds\n",
      "\n",
      "CPU TRAIN METRICS:\n",
      "Accuracy: 0.916 | F1-score: 0.933 | AUC: 0.959\n",
      "\n",
      "CPU TEST METRICS:\n",
      "Accuracy: 0.922 | F1-score: 0.937 | AUC: 0.959\n",
      "\n",
      "CPU VALIDATION METRICS:\n",
      "Accuracy: 0.923 | F1-score: 0.938 | AUC: 0.959\n",
      "\n",
      "=== GPU ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 26\u001B[39m\n\u001B[32m     23\u001B[39m run_and_report(\u001B[33m\"\u001B[39m\u001B[33mCPU\u001B[39m\u001B[33m\"\u001B[39m, torch.device(\u001B[33m\"\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch.cuda.is_available():\n\u001B[32m---> \u001B[39m\u001B[32m26\u001B[39m     \u001B[43mrun_and_report\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mGPU\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcuda\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     28\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mGPU not available. Skipping GPU training.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 5\u001B[39m, in \u001B[36mrun_and_report\u001B[39m\u001B[34m(device_label, device)\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m=== \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice_label\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m ===\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      4\u001B[39m start_time = time()\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m model = \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      6\u001B[39m duration = time() - start_time\n\u001B[32m      8\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice_label\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m TRAINING TIME: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mduration\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m seconds\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 11\u001B[39m, in \u001B[36mtrain_model\u001B[39m\u001B[34m(X_train, y_train, device, epochs, batch_size, lr)\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[32m     10\u001B[39m     model.train()\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mxb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43myb\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mloader\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m        \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mzero_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m#needed to clear gradients because PyTorch accumulates gradients by default\u001B[39;49;00m\n\u001B[32m     13\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpred\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxb\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43msqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Studia\\Sem4\\Metody - laby\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    730\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    731\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    732\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m733\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    734\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    735\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    736\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    737\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    738\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    739\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Studia\\Sem4\\Metody - laby\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    787\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    788\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m789\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    790\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    791\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Studia\\Sem4\\Metody - laby\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     data = \u001B[38;5;28mself\u001B[39m.dataset[possibly_batched_index]\n\u001B[32m---> \u001B[39m\u001B[32m55\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Studia\\Sem4\\Metody - laby\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001B[39m, in \u001B[36mdefault_collate\u001B[39m\u001B[34m(batch)\u001B[39m\n\u001B[32m    337\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdefault_collate\u001B[39m(batch):\n\u001B[32m    338\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    339\u001B[39m \u001B[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001B[39;00m\n\u001B[32m    340\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    396\u001B[39m \u001B[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001B[39;00m\n\u001B[32m    397\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m398\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdefault_collate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Studia\\Sem4\\Metody - laby\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001B[39m, in \u001B[36mcollate\u001B[39m\u001B[34m(batch, collate_fn_map)\u001B[39m\n\u001B[32m    208\u001B[39m transposed = \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(*batch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[32m    210\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m    211\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[32m--> \u001B[39m\u001B[32m212\u001B[39m         \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    213\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed\n\u001B[32m    214\u001B[39m     ]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[32m    215\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    216\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Studia\\Sem4\\Metody - laby\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001B[39m, in \u001B[36mcollate\u001B[39m\u001B[34m(batch, collate_fn_map)\u001B[39m\n\u001B[32m    153\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m collate_fn_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    154\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m elem_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[32m--> \u001B[39m\u001B[32m155\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate_fn_map\u001B[49m\u001B[43m[\u001B[49m\u001B[43melem_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    157\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m collate_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[32m    158\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, collate_type):\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Studia\\Sem4\\Metody - laby\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001B[39m, in \u001B[36mcollate_tensor_fn\u001B[39m\u001B[34m(batch, collate_fn_map)\u001B[39m\n\u001B[32m    270\u001B[39m     storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n\u001B[32m    271\u001B[39m     out = elem.new(storage).resize_(\u001B[38;5;28mlen\u001B[39m(batch), *\u001B[38;5;28mlist\u001B[39m(elem.size()))\n\u001B[32m--> \u001B[39m\u001B[32m272\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
