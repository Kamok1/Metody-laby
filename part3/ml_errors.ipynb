{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from constants import numeric_features, categorical_features\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from part2.shared import load_processed_data\n",
    "from part2.shared import load_train_with_validation_data\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "NUMBER_OF_EPOCHS = 250",
   "id": "1323c22961a987fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df = load_processed_data()\n",
    "df = df[df[\"Target\"].isin([\"Graduate\", \"Dropout\"])]\n",
    "df[\"y\"] = (df[\"Target\"] == \"Graduate\").astype(int)\n",
    "df = df.drop(columns=[\"Target\", \"Target encoded\"], errors='ignore')"
   ],
   "id": "2b1b7ae7b8475858",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = df.drop(columns=[\"y\"])\n",
    "y = df[\"y\"].values"
   ],
   "id": "c5b948b62fa9daf4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_features = [c for c in numeric_features if c in X.columns]\n",
    "cat_features = [c for c in categorical_features if c in X.columns]"
   ],
   "id": "d090a12c168e7af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])"
   ],
   "id": "41cf71974728f833",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])"
   ],
   "id": "5ab0f40c5a26950c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_features),\n",
    "    (\"cat\", cat_pipeline, cat_features)\n",
    "])"
   ],
   "id": "c0a403081ce9a113",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_raw, X_val_raw, X_test_raw, y_train, y_val, y_test = load_train_with_validation_data(X, y)\n",
    "X_train = full_pipeline.fit_transform(X_train_raw)\n",
    "X_test = full_pipeline.transform(X_test_raw)\n",
    "X_val = full_pipeline.transform(X_val_raw)"
   ],
   "id": "6aebfd4ae1e6b98a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from Logistic import CustomLogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "X_train = full_pipeline.fit_transform(X_train_raw)\n",
    "X_val = full_pipeline.transform(X_val_raw)\n",
    "X_test = full_pipeline.transform(X_test_raw)\n",
    "\n",
    "X_train_bias = np.hstack([np.ones((X_train.shape[0], 1)), X_train.toarray()])\n",
    "X_val_bias = np.hstack([np.ones((X_val.shape[0], 1)), X_val.toarray()])\n",
    "X_test_bias = np.hstack([np.ones((X_test.shape[0], 1)), X_test.toarray()])\n",
    "\n",
    "baseline_clf = CustomLogisticRegression(\n",
    "    lr=0.05,\n",
    "    epochs=250,\n",
    "    batch_size=64,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "baseline_clf.fit(X_train_bias, y_train, X_val_bias, y_val, X_test_bias, y_test)\n"
   ],
   "id": "70779b24cfb25286",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(baseline_clf.history['train'], label=\"Train loss\")\n",
    "plt.plot(baseline_clf.history['test'], label=\"Train loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Log loss\")\n",
    "plt.title(\"Zbieżność CustomLogisticRegression\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "cf90d14efa5fb434",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_pipeline = ColumnTransformer([\n",
    "    (\"num_poly\", Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "        (\"sc\", StandardScaler())\n",
    "    ]), num_features),\n",
    "    (\"cat\", cat_pipeline, cat_features)\n",
    "])\n"
   ],
   "id": "1c9c6699dcd912b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_poly = poly_pipeline.fit_transform(X_train_raw)\n",
    "X_val_poly   = poly_pipeline.transform(X_val_raw)\n",
    "X_test_poly  = poly_pipeline.transform(X_test_raw)\n",
    "\n",
    "X_train_poly_bias = np.hstack([np.ones((X_train_poly.shape[0], 1)), X_train_poly])\n",
    "X_val_poly_bias   = np.hstack([np.ones((X_val_poly.shape[0], 1)), X_val_poly])\n",
    "X_test_poly_bias  = np.hstack([np.ones((X_test_poly.shape[0], 1)), X_test_poly])\n",
    "\n",
    "model_poly = CustomLogisticRegression(\n",
    "    lr=0.05,\n",
    "    epochs=NUMBER_OF_EPOCHS,\n",
    "    batch_size=64,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "model_poly.fit(X_train_poly_bias, y_train, X_val_poly_bias, y_val, X_test_poly_bias, y_test)"
   ],
   "id": "932333f756995c42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(model_poly.history[\"train\"], label=\"Train loss (poly)\")\n",
    "plt.plot(model_poly.history[\"val\"], label=\"Validation loss (poly)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Log loss\")\n",
    "plt.title(\"Zbieżność – model z PolynomialFeatures\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "4c9f96b4b730ac73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred_poly = model_poly.predict(X_test_poly_bias)\n",
    "print(classification_report(y_test, y_pred_poly, digits=4))\n"
   ],
   "id": "b703220b551b7cb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "select_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"selector\", SelectKBest(score_func=f_classif, k=5)),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "X_train_selected = select_pipeline.fit_transform(X_train_raw[num_features], y_train)\n",
    "X_val_selected = select_pipeline.transform(X_val_raw[num_features])\n",
    "X_test_selected = select_pipeline.transform(X_test_raw[num_features])\n",
    "\n",
    "# bias\n",
    "X_train_sel_bias = np.hstack([np.ones((X_train_selected.shape[0], 1)), X_train_selected])\n",
    "X_val_sel_bias = np.hstack([np.ones((X_val_selected.shape[0], 1)), X_val_selected])\n",
    "X_test_sel_bias = np.hstack([np.ones((X_test_selected.shape[0], 1)), X_test_selected])\n",
    "\n",
    "# nowy model\n",
    "model_sel = CustomLogisticRegression(lr=0.05, epochs=250, batch_size=64, verbose=True)\n",
    "model_sel.fit(X_train_sel_bias, y_train, X_val_sel_bias, y_val, X_test_sel_bias, y_test)"
   ],
   "id": "d6505bdd9faa312b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(model_sel.history[\"train\"], label=\"Train loss (selected features)\")\n",
    "plt.plot(model_sel.history[\"val\"], label=\"Val loss (selected features)\")\n",
    "plt.plot(model_sel.history[\"test\"], label=\"Test loss (selected features)\")\n",
    "plt.title(\"Zbieżność – po selekcji 5 najlepszych cech\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Log loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "f16dc6c1d3b190a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T17:41:07.453426Z",
     "start_time": "2025-05-30T17:41:07.439399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred_sel = model_sel.predict(X_test_sel_bias)\n",
    "print(classification_report(y_test, y_pred_sel, digits=4))"
   ],
   "id": "3de568671b328d38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9065    0.7852    0.8415       284\n",
      "           1     0.8732    0.9481    0.9091       443\n",
      "\n",
      "    accuracy                         0.8845       727\n",
      "   macro avg     0.8898    0.8666    0.8753       727\n",
      "weighted avg     0.8862    0.8845    0.8827       727\n",
      "\n"
     ]
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
